services:
  # ===========================================
  # Zookeeper 服务 - Kafka 的协调者
  # ===========================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: ${ZOOKEEPER_HOST}
    container_name: zookeeper
    ports:
      - "${ZOOKEEPER_PORT}:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_PORT}
      ZOOKEEPER_TICK_TIME: ${ZOOKEEPER_TICK_TIME}
    networks:
      - ${NETWORK_NAME}
    restart: unless-stopped

  # ===========================================
  # Kafka 服务 - 事件总线（用于流式计算场景）
  # ===========================================
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: ${KAFKA_HOST}
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "${KAFKA_EXTERNAL_PORT}:9092"
      - "${KAFKA_JMX_PORT}:9101"
    environment:
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID}
      KAFKA_ZOOKEEPER_CONNECT: '${ZOOKEEPER_HOST}:${ZOOKEEPER_PORT}'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${KAFKA_HOST}:${KAFKA_INTERNAL_PORT},PLAINTEXT_HOST://localhost:${KAFKA_EXTERNAL_PORT}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR}
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: ${KAFKA_TRANSACTION_STATE_LOG_MIN_ISR}
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: ${KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS}
      KAFKA_JMX_PORT: ${KAFKA_JMX_PORT}
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: '${KAFKA_AUTO_CREATE_TOPICS_ENABLE}'
    networks:
      - ${NETWORK_NAME}
    restart: unless-stopped

  # ===========================================
  # MySQL 服务 - 业务交易数据库
  # ===========================================
  mysql:
    image: mysql:8.0
    hostname: ${MYSQL_HOST}
    container_name: mysql
    ports:
      - "${MYSQL_EXTERNAL_PORT}:3306"
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_CDC_USER}
      MYSQL_PASSWORD: ${MYSQL_CDC_PASSWORD}
    volumes:
      - mysql_data:/var/lib/mysql
      - ./mysql-init:/docker-entrypoint-initdb.d
    command:
      - --server-id=1
      - --log-bin=mysql-bin
      - --binlog-format=row
      - --binlog-row-image=full
      - --expire-logs-days=10
      - --binlog-do-db=${MYSQL_DATABASE}
      - --gtid-mode=on
      - --enforce-gtid-consistency=on
    networks:
      - ${NETWORK_NAME}
    restart: unless-stopped

  # ===========================================
  # Flink JobManager 服务 - 流处理作业管理器
  # 支持 Flink CDC 连接器
  # ===========================================
  flink-jobmanager:
    image: flink:1.18.0-scala_2.12
    hostname: ${FLINK_JOBMANAGER_HOST}
    container_name: flink-jobmanager
    ports:
      - "${FLINK_JOBMANAGER_WEB_PORT}:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: ${FLINK_JOBMANAGER_HOST}
        taskmanager.numberOfTaskSlots: ${FLINK_TASKMANAGER_SLOTS}
        parallelism.default: ${FLINK_PARALLELISM_DEFAULT}
        state.backend: ${FLINK_STATE_BACKEND}
        state.checkpoints.dir: ${FLINK_CHECKPOINT_DIR}
        state.savepoints.dir: ${FLINK_SAVEPOINT_DIR}
        execution.checkpointing.interval: ${FLINK_CHECKPOINT_INTERVAL}
        execution.checkpointing.externalized-checkpoint-retention: ${FLINK_CHECKPOINT_RETENTION}
    volumes:
      - flink_data:/tmp/flink-checkpoints
      - flink_savepoints:/tmp/flink-savepoints
      - ./flink-lib:/opt/flink/lib/custom
    networks:
      - ${NETWORK_NAME}
    restart: unless-stopped

  # ===========================================
  # Flink TaskManager 服务 - 流处理任务执行器
  # ===========================================
  flink-taskmanager:
    image: flink:1.18.0-scala_2.12
    depends_on:
      - flink-jobmanager
    command: taskmanager
    scale: ${FLINK_TASKMANAGER_SCALE}
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: ${FLINK_JOBMANAGER_HOST}
        taskmanager.numberOfTaskSlots: ${FLINK_TASKMANAGER_SLOTS}
        parallelism.default: ${FLINK_PARALLELISM_DEFAULT}
        state.backend: ${FLINK_STATE_BACKEND}
        taskmanager.memory.process.size: ${FLINK_TASKMANAGER_MEMORY_PROCESS_SIZE}
        taskmanager.memory.flink.size: ${FLINK_TASKMANAGER_MEMORY_FLINK_SIZE}
    volumes:
      - ./flink-lib:/opt/flink/lib/custom
    networks:
      - ${NETWORK_NAME}
    restart: unless-stopped

  # ===========================================
  # AKHQ 服务 - Kafka UI 管理工具
  # ===========================================
  akhq:
    image: tchiotludo/akhq:0.24.0
    hostname: ${AKHQ_HOST}
    container_name: akhq
    depends_on:
      - kafka
    ports:
      - "${AKHQ_PORT}:8080"
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "${KAFKA_HOST}:${KAFKA_INTERNAL_PORT}"
              schema-registry:
                url: "http://${SCHEMA_REGISTRY_HOST}:${SCHEMA_REGISTRY_PORT}"
    networks:
      - ${NETWORK_NAME}
    restart: unless-stopped

  # ===========================================
  # Schema Registry 服务 - 模式注册表
  # ===========================================
  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.0
    hostname: ${SCHEMA_REGISTRY_HOST}
    container_name: schema-registry
    depends_on:
      - kafka
    ports:
      - "${SCHEMA_REGISTRY_EXTERNAL_PORT}:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: ${SCHEMA_REGISTRY_HOST}
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: '${KAFKA_HOST}:${KAFKA_INTERNAL_PORT}'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:${SCHEMA_REGISTRY_PORT}
    networks:
      - ${NETWORK_NAME}
    restart: unless-stopped

  # ===========================================
  # Flink CDC 初始化服务 - 下载必要的 JAR 包
  # ===========================================
  flink-cdc-init:
    image: alpine:latest
    container_name: flink-cdc-init
    volumes:
      - ./flink-lib:/flink-lib
    command: |
      sh -c "
        apk add --no-cache wget &&
        mkdir -p /flink-lib &&
        echo '下载 Flink CDC MySQL 连接器...' &&
        wget -O /flink-lib/flink-sql-connector-mysql-cdc-2.4.2.jar 'https://repo1.maven.org/maven2/com/ververica/flink-sql-connector-mysql-cdc/2.4.2/flink-sql-connector-mysql-cdc-2.4.2.jar' ||
        echo '请手动下载 flink-sql-connector-mysql-cdc-2.4.2.jar 到 ./flink-lib/ 目录' &&
        echo '下载 Flink Kafka 连接器...' &&
        wget -O /flink-lib/flink-sql-connector-kafka-1.18.0.jar 'https://repo1.maven.org/maven2/org/apache/flink/flink-sql-connector-kafka/1.18.0/flink-sql-connector-kafka-1.18.0.jar' ||
        echo '请手动下载 flink-sql-connector-kafka-1.18.0.jar 到 ./flink-lib/ 目录' &&
        echo '下载 MySQL JDBC 驱动...' &&
        wget -O /flink-lib/mysql-connector-java-8.0.33.jar 'https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.33/mysql-connector-java-8.0.33.jar' ||
        echo '请手动下载 mysql-connector-java-8.0.33.jar 到 ./flink-lib/ 目录' &&
        echo 'Flink CDC 连接器初始化完成'
      "
    networks:
      - ${NETWORK_NAME}

# ===========================================
# 数据卷配置
# ===========================================
volumes:
  mysql_data:
    driver: local
  flink_data:
    driver: local
  flink_savepoints:
    driver: local

# ===========================================
# 网络配置 - 确保所有服务在同一网络中
# ===========================================
networks:
  stream-batch-network:
    name: ${NETWORK_NAME}
    driver: bridge 